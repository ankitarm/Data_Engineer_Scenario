{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNtzZ1kNfx6kCK8t/mNs5OT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitarm/Data_Engineer_Scenario/blob/main/Data_Eengineer_Mocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c-NvqsrhYp1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mock 1 : https://www.youtube.com/watch?v=-iMhSpP77F8"
      ],
      "metadata": {
        "id": "nQpEwDg0Yrb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2. Please explain what Kinesis is and its role.\n",
        "### **What is AWS Kinesis?**  \n",
        "AWS Kinesis is a **fully managed, scalable, real-time data streaming service** provided by Amazon Web Services (AWS). It is designed to **collect, process, and analyze streaming data** (e.g., logs, metrics, transactions, social media feeds) in real time.  \n",
        "\n",
        "Kinesis is often compared to **Apache Kafka** (an open-source distributed event streaming platform), but unlike Kafka, Kinesis is **fully managed by AWS**, eliminating the need to handle cluster setup, scaling, or maintenance.\n",
        "\n",
        "---\n",
        "\n",
        " **Key Components of Kinesis**  \n",
        "Kinesis consists of multiple services, each serving different streaming needs:  \n",
        "\n",
        "1. **Kinesis Data Streams**  \n",
        "   - **Role:** Ingests and stores real-time data records (e.g., clickstreams, IoT sensor data).  \n",
        "\n",
        "2. **Kinesis Data Firehose**  \n",
        "   - **Role:** **Automatically loads streaming data into AWS destinations** (S3, Redshift, Elasticsearch, etc.).  \n"
      ],
      "metadata": {
        "id": "vYptpEUvY7eO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3. Can you elaborate more on diff between kafka and kinesis\n",
        "\n",
        "\n",
        "| **Feature**               | **Apache Kafka**                                   | **AWS Kinesis**                                  |\n",
        "|---------------------------|---------------------------------------------------|-------------------------------------------------|\n",
        "| **Managed Service**       | Self-hosted (requires setup/maintenance)          | Fully managed by AWS                            |\n",
        "| **Scalability**           | Manual scaling (add brokers/partitions)           | Auto-scaling (adjust shards dynamically)        |\n",
        "| **Latency**               | Ultra-low (~10ms)                                 | Higher (~200ms)                                 |\n",
        "| **Durability**            | Configurable replication (user-managed)           | Built-in replication across AZs                 |\n",
        "| **Pricing Model**         | Open-source (infrastructure costs apply)          | Pay per shard/hour + data volume               |\n",
        "| **Data Retention**         | Configurable (days to years)                      | Fixed (1–365 days)                              |\n",
        "| **Throughput**            | Higher (supports 100k+ msgs/sec per partition)    | Lower (1MB/sec or 1k msgs/sec per shard)       |\n",
        "| **Partitions/Shards**     | Partitions (user-managed)                         | Shards (AWS-managed)                            |\n",
        "| **Integrations**          | Multi-cloud, on-prem, hybrid                      | AWS-native (Lambda, S3, Redshift, etc.)        |\n",
        "| **Use Cases**             | High-throughput, low-latency, cross-platform apps | Real-time analytics, AWS-centric pipelines     |\n",
        "| **Setup Complexity**      | High (requires tuning, monitoring)                | Low (serverless, minimal configuration)        |\n",
        "| **Security**              | Custom (SSL, SASL, Kerberos)                      | AWS IAM, KMS encryption                        |\n",
        "| **Consumer Model**        | Pull-based (consumers request data)               | Push/pull hybrid (Kinesis Client Library)      |\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Takeaways:**\n",
        "1. **Choose Kafka** if you need:  \n",
        "   - Cross-platform deployment (e.g., hybrid cloud).  \n",
        "   - Ultra-low latency (e.g., financial trading).  \n",
        "   - Full control over infrastructure.  \n",
        "\n",
        "2. **Choose Kinesis** if you:  \n",
        "   - Prefer a serverless, AWS-native solution.  \n",
        "   - Need quick setup without managing clusters.  \n",
        "   - Use AWS services (e.g., Lambda, Firehose).  \n",
        "\n",
        "Which to Choose?\n",
        "Need long retention (years) or flexibility? → Kafka.\n",
        "\n",
        "Want simplicity and AWS integration? → Kinesis (but max 1 year)."
      ],
      "metadata": {
        "id": "GbNVrdbXdpum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4. **Kafka vs. Kinesis: Producer-Consumer or Pub/Sub?**  \n",
        "\n",
        "\n",
        "| **Model Aspect**       | **Apache Kafka**                                   | **AWS Kinesis**                                  |\n",
        "|------------------------|---------------------------------------------------|-------------------------------------------------|\n",
        "| **Primary Model**      | **Pub/Sub** (with consumer groups)                | **Producer-Consumer** (with shard-level parallelism) |\n",
        "| **Data Flow**          | - Producers → **Topics** → Consumers (pull-based) | - Producers → **Streams/Shards** → Consumers (push/pull hybrid) |\n",
        "| **Subscription Style** | - Consumers **subscribe to topics** (flexible)    | - Consumers **read from shards** (fixed mapping) |\n",
        "| **Message Delivery**   | - **Pull-based** (consumers request data)         | - **Push (KCL) or Pull (Lambda, SDKs)**         |\n",
        "| **Parallelism**        | - **Partitions** allow parallel consumers         | - **Shards** enable parallel processing         |\n",
        "| **Decoupling**         | - High (multiple consumer groups per topic)       | - Medium (consumers compete for shard leases)   |\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Differences**  \n",
        "1. **Kafka = Pub/Sub with Flexibility**  \n",
        "   - Producers publish to **topics**, and **consumer groups** subscribe.  \n",
        "   - Multiple independent consumer groups can read the same data (e.g., one for analytics, another for alerts).  \n",
        "   - Example:  \n",
        "     ```python\n",
        "     # Kafka Pub/Sub Example\n",
        "     producer.send(\"orders-topic\", order_data)  # Publisher\n",
        "     consumer.subscribe([\"orders-topic\"])      # Subscriber\n",
        "     ```\n",
        "\n",
        "2. **Kinesis = Producer-Consumer with Scalability**  \n",
        "   - Producers write to **shards**, and consumers **lease shards** for processing.  \n",
        "   - Each shard supports **one consumer at a time** (no native fan-out).  \n",
        "   - Example:  \n",
        "     ```python\n",
        "     # Kinesis Producer-Consumer Example\n",
        "     kinesis.put_record(StreamName=\"logs-stream\", Data=log_data)  # Producer\n",
        "     shard_reader = kinesis.get_shard_iterator(...)               # Consumer\n",
        "     ```\n",
        "\n"
      ],
      "metadata": {
        "id": "dfix4F_Le-mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5. What is the difference between producer-consumer and publisher-subscriber?\n",
        "\n",
        "### **Producer-Consumer vs. Publisher-Subscriber**  \n",
        "\n",
        "These are two fundamental messaging patterns in distributed systems, differing in **coupling**, **scalability**, and **message delivery** mechanics.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Producer-Consumer Model**  \n",
        "**Definition:**  \n",
        "- A **synchronous, point-to-point** messaging pattern.  \n",
        "- **Producers** send messages to a **queue**, and **consumers** pull messages from it.  \n",
        "- Each message is processed by **exactly one consumer**.  \n",
        "\n",
        "**Key Traits:**  \n",
        "✅ **Point-to-Point (1:1)** – Only one consumer gets each message.  \n",
        "✅ **Tight Coupling** – Producers/consumers must know the queue.  \n",
        "✅ **Pull-Based** – Consumers request messages when ready.  \n",
        "✅ **Order Guaranteed** – FIFO (First-In-First-Out) by default.  \n",
        "\n",
        "**Example:**  \n",
        "- A **task queue** (e.g., RabbitMQ, SQS).  \n",
        "- Workers processing orders from an e-commerce system.  \n",
        "\n",
        "**Diagram:**  \n",
        "```\n",
        "Producer → [ Queue ] → Consumer\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Publisher-Subscriber (Pub/Sub) Model**  \n",
        "**Definition:**  \n",
        "- An **asynchronous, broadcast** messaging pattern.  \n",
        "- **Publishers** send messages to a **topic**, and **subscribers** receive them.  \n",
        "- Each message is processed by **all interested subscribers**.  \n",
        "\n",
        "**Key Traits:**  \n",
        "✅ **Broadcast (1:N)** – Multiple subscribers receive the same message.  \n",
        "✅ **Loose Coupling** – Publishers/subscribers only know the topic, not each other.  \n",
        "✅ **Push-Based** – Messages are pushed to subscribers (or pulled via polling).  \n",
        "✅ **Dynamic Scaling** – Subscribers can join/leave anytime.  \n",
        "\n",
        "**Example:**  \n",
        "- **Stock market feeds** (multiple apps listen to price updates).  \n",
        "- **Event-driven microservices** (e.g., Kafka, AWS SNS).  \n",
        "\n",
        "**Diagram:**  \n",
        "```\n",
        "Publisher → [ Topic ] → Subscriber 1  \n",
        "                     → Subscriber 2  \n",
        "                     → Subscriber 3\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **Key Differences Summary**  \n",
        "| **Aspect**          | **Producer-Consumer**                | **Publisher-Subscriber**             |\n",
        "|----------------------|--------------------------------------|--------------------------------------|\n",
        "| **Messaging Style**  | Point-to-point (1:1)                 | Broadcast (1:N)                      |\n",
        "| **Coupling**         | Tight (queue-aware)                  | Loose (topic-based)                  |\n",
        "| **Delivery**         | Pull-based (consumer-driven)         | Push-based (or polled)               |\n",
        "| **Scalability**      | Limited (competing consumers)        | High (independent subscribers)       |\n",
        "| **Use Cases**        | Task queues, ordered processing      | Real-time notifications, event buses |\n",
        "\n",
        "---\n",
        "\n",
        "### **Which to Choose?**  \n",
        "- **Use Producer-Consumer** when:  \n",
        "  - You need **exactly-once processing** (e.g., order fulfillment).  \n",
        "  - Order matters (e.g., FIFO queues).  \n",
        "\n",
        "- **Use Pub/Sub** when:  \n",
        "  - Multiple systems need **the same data** (e.g., analytics + alerts).  \n",
        "  - You want **decoupled, event-driven architectures**.  \n",
        "\n",
        "**Hybrid Systems (Kafka/Kinesis):**  \n",
        "- Both models can coexist (e.g., Kafka uses **consumer groups** for Pub/Sub-like behavior while maintaining ordering per partition).  \n",
        "\n",
        "Would you like a real-world analogy (e.g., postal service vs. radio broadcast)?"
      ],
      "metadata": {
        "id": "t4kLAuOyh0Oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6. Why are Kafka or Kinesis used instead of simple messaging queues?\n",
        "\n",
        "### **Message Ordering in Kafka vs. Kinesis**  \n",
        "\n",
        "#### **✅ Kafka**  \n",
        "- **Ordered per partition**: Messages in the same partition are strictly ordered (FIFO).  \n",
        "- **No global order**: Across partitions, order is **not** guaranteed unless using a single partition (bottleneck).  \n",
        "- **Key-based routing**: Same key → same partition → preserves order for related messages.  \n",
        "- **Use case**: E.g., ensuring all events for a user ID are processed in sequence.  \n",
        "\n",
        "#### **✅ Kinesis**  \n",
        "- **Ordered per shard**: Messages in the same shard are strictly ordered.  \n",
        "- **No cross-shard order**: Like Kafka, order is lost across shards.  \n",
        "- **Partition key routing**: Same key → same shard → ordered sequence.  \n",
        "- **Use case**: E.g., processing financial transactions in exact arrival order per account.  \n",
        "\n",
        "#### **⚠️ Key Limitation**  \n",
        "- Both **cannot guarantee global order** (across partitions/shard) without sacrificing scalability.  \n"
      ],
      "metadata": {
        "id": "QzuR7OQMj-lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7. Can messages be ordered in Kafka or Kinesis?\n",
        "\n",
        "### **Message Ordering in Kafka vs. Kinesis**  \n",
        "\n",
        "**Short Answer:**  \n",
        "Yes, but **only within a partition (Kafka) or shard (Kinesis)**. Global ordering across all partitions/shard is **not guaranteed**.  \n",
        "\n",
        "#### **Kafka**  \n",
        "- **Order Guarantee**: Strictly ordered **per partition**.  \n",
        "  - Example: If messages M1, M2, M3 are sent to **Partition 1**, they’ll be consumed in order.  \n",
        "  - Cross-partition order is **not guaranteed** (e.g., M1 in Partition 1 and M4 in Partition 2 may arrive out of order).  \n",
        "- **How to Preserve Order**:  \n",
        "  - Use a **message key** (e.g., `user_id`) to ensure related messages go to the same partition.  \n",
        "\n",
        "#### **Kinesis**  \n",
        "- **Order Guarantee**: Strictly ordered **per shard**.  \n",
        "  - Example: Messages in **Shard A** are ordered, but Shard A vs. Shard B may deliver data out of sequence.  \n",
        "- **How to Preserve Order**:  \n",
        "  - Use a **partition key** (e.g., `device_id`) to route related messages to the same shard.  \n",
        "\n",
        "---\n",
        "\n",
        "### **When Order Matters**  \n",
        "- **Use Cases**:  \n",
        "  - **Kafka**: Financial transactions (e.g., debit before credit).  \n",
        "  - **Kinesis**: Clickstream sequences (e.g., page A → page B).  \n",
        "- **Trade-off**:  \n",
        "  - Ordering reduces parallelism (since keys must map to the same partition/shard).  \n",
        "\n",
        "---\n",
        "\n",
        "### **Interview Tip**  \n",
        "*\"Kafka and Kinesis guarantee ordering only within a partition/shard. For global ordering, you’d need a single partition (which limits throughput) or external sequencing (like a ledger).\"*  \n",
        "\n"
      ],
      "metadata": {
        "id": "_CIJdDQ7lQGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8. **Priority Queue: Definition & Key Concepts**  \n",
        "A **priority queue** is a specialized data structure where elements are processed based on **priority** (not just insertion order).  \n",
        "\n",
        "#### **Key Characteristics (Bullet Points)**  \n",
        "- **Not FIFO**: Unlike regular queues, the **highest-priority** element is removed first.  \n",
        "- **Priority Assignment**: Each element has an associated priority (e.g., numerical value, urgency level).  \n",
        "- **Operations**:  \n",
        "  - **Insert**: Add an element with a priority.  \n",
        "  - **Extract**: Remove the highest/lowest priority element.  \n",
        "- **Implementation**: Typically uses a **heap** (binary heap) for efficient O(log n) inserts/extracts.  \n",
        "\n",
        "#### **Real-World Examples**  \n",
        "- **Hospital ER**: Critical patients (high priority) are treated before mild cases.  \n",
        "- **CPU Scheduling**: High-priority tasks (e.g., system processes) run before background apps.  \n",
        "- **Ride-Sharing**: Premium users get faster driver allocation.  \n",
        "\n",
        "\n",
        "#### **Example in Python**  \n",
        "```python\n",
        "import heapq\n",
        "\n",
        "pq = []\n",
        "heapq.heappush(pq, (2, \"Task A\"))  # (priority, data)\n",
        "heapq.heappush(pq, (1, \"Task B\"))  # Lower number = higher priority\n",
        "print(heapq.heappop(pq)[1])         # Output: \"Task B\" (higher priority)\n",
        "```\n",
        "\n",
        "#### **Interview Tip**  \n",
        "- Mention trade-offs: **Heaps** (O(log n)) vs. **sorted lists** (O(n) insert).  \n",
        "- Use cases where order matters beyond FIFO (e.g., real-time systems).  \n",
        "\n"
      ],
      "metadata": {
        "id": "L2_k8cJMn-71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9. **Process vs. Thread (Short Interview Answer)**  \n",
        "\n",
        "- **Process**:  \n",
        "  - Independent program instance with **separate memory** (isolated).  \n",
        "  - Heavyweight (slower to create/switch).  \n",
        "  - Crash in one process **doesn’t affect others**.  \n",
        "\n",
        "- **Thread**:  \n",
        "  - Lightweight **subset of a process**, shares memory/resources.  \n",
        "  - Faster to create/switch (less overhead).  \n",
        "  - Crash in one thread **can crash the entire process**.  \n",
        "\n",
        "**Key Difference**:  \n",
        "- Processes = **Isolated execution** (e.g., separate browser tabs).  \n",
        "- Threads = **Parallel tasks within a process** (e.g., rendering + downloads in one tab).  \n"
      ],
      "metadata": {
        "id": "cO2NI6TYo1mD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10. **CAP Theorem: Short & Clear Explanation**  \n",
        "\n",
        "**CAP Theorem** states that in a distributed system, you can only guarantee **two out of three** properties at the same time:  \n",
        "\n",
        "1. **Consistency (C)**  \n",
        "   - All nodes see the **same data at the same time** (e.g., a bank balance is accurate across all servers).  \n",
        "\n",
        "2. **Availability (A)**  \n",
        "   - Every request gets a **response (even if stale)**, with no system downtime.  \n",
        "\n",
        "3. **Partition Tolerance (P)**  \n",
        "   - The system keeps working **even if nodes disconnect** (e.g., network failure).  \n",
        "\n",
        "#### **Trade-offs (Pick 2/3)**  \n",
        "- **CA** (e.g., SQL databases): Sacrifice partition tolerance (single-server systems).  \n",
        "- **CP** (e.g., MongoDB, Kafka): Sacrifice availability (e.g., reject requests if nodes can’t sync).  \n",
        "- **AP** (e.g., Cassandra, DynamoDB): Sacrifice consistency (allow stale reads during partitions).  \n",
        "\n",
        "### **Real-World Examples of CAP Theorem Trade-offs**  \n",
        "\n",
        "#### **1. CP (Consistency + Partition Tolerance)**  \n",
        "**Example: Banks & Financial Systems**  \n",
        "- **Why?** Transactions **must** be consistent (e.g., $100 withdrawn can’t show $90 in one server and $100 in another).  \n",
        "- **Sacrifice:** Availability (e.g., during a network partition, the system may reject transactions to avoid inconsistencies).  \n",
        "- **Tech:** PostgreSQL, Kafka (for transactions), Zookeeper.  \n",
        "\n",
        "#### **2. AP (Availability + Partition Tolerance)**  \n",
        "**Example: Social Media (Facebook, Twitter)**  \n",
        "- **Why?** Better to show **stale data** (e.g., delayed like counts) than fail to load the page.  \n",
        "- **Sacrifice:** Consistency (temporary mismatches are acceptable).  \n",
        "- **Tech:** Cassandra, DynamoDB, Redis (eventual consistency).  \n",
        "\n",
        "#### **3. CA (Consistency + Availability)**  \n",
        "**Example: Single-Node Databases (Rare in Distributed Systems)**  \n",
        "- **Why?** No partitions (single server), so it’s always consistent and available.  \n",
        "- **Sacrifice:** Partition tolerance (fails if the network splits).  \n",
        "- **Tech:** SQLite, standalone MySQL (non-replicated).  \n",
        "\n",
        "### **Key Insight**  \n",
        "- **Most distributed systems choose **CP or AP** (since partitions are inevitable).  \n",
        "- **CA systems** are rare in modern cloud architectures (they’re not fault-tolerant).  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uYIcHd-vsJO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q11. SQL Query to Find Percentage of Users Who Bought AirPods After iPhones\n",
        "\n",
        "To solve this problem, we need to:\n",
        "1. Identify users who bought an iPhone\n",
        "2. Check if their next purchase was AirPods\n",
        "3. Calculate the percentage of such users out of all iPhone buyers\n",
        "\n",
        "Here's the SQL solution:\n",
        "\n",
        "```sql\n",
        "WITH UserPurchaseSequence AS (\n",
        "    SELECT\n",
        "        customer_id,\n",
        "        product,\n",
        "        transaction_timestamp,\n",
        "        LEAD(product) OVER (PARTITION BY customer_id ORDER BY transaction_timestamp) AS next_product\n",
        "    FROM transactions\n",
        "),\n",
        "\n",
        "iPhoneBuyers AS (\n",
        "    SELECT DISTINCT customer_id\n",
        "    FROM transactions\n",
        "    WHERE product = 'iPhone'\n",
        "),\n",
        "\n",
        "iPhoneToAirPodsBuyers AS (\n",
        "    SELECT DISTINCT customer_id\n",
        "    FROM UserPurchaseSequence\n",
        "    WHERE product = 'iPhone' AND next_product = 'AirPods'\n",
        ")\n",
        "\n",
        "SELECT\n",
        "    (COUNT(DISTINCT iab.customer_id) * 100.0 /\n",
        "    NULLIF(COUNT(DISTINCT ib.customer_id), 0) AS percentage\n",
        "FROM iPhoneBuyers ib\n",
        "LEFT JOIN iPhoneToAirPodsBuyers iab ON ib.customer_id = iab.customer_id;\n",
        "```\n",
        "\n",
        "## Explanation:\n",
        "\n",
        "1. **UserPurchaseSequence CTE**:\n",
        "   - Uses the `LEAD()` window function to see what each customer bought next\n",
        "   - Partitions by customer and orders by timestamp to get chronological sequence\n",
        "\n",
        "2. **iPhoneBuyers CTE**:\n",
        "   - Identifies all unique customers who bought iPhones (denominator)\n",
        "\n",
        "3. **iPhoneToAirPodsBuyers CTE**:\n",
        "   - Finds customers whose immediate next purchase after iPhone was AirPods (numerator)\n",
        "\n",
        "4. **Final Calculation**:\n",
        "   - Divides the count of customers who bought AirPods after iPhones by total iPhone buyers\n",
        "   - Multiplies by 100 to get percentage\n",
        "   - Uses NULLIF to avoid division by zero\n"
      ],
      "metadata": {
        "id": "q2vfJS3Qtf0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q12. Will the code work if you try to delete dictionary items during iteration?\n",
        "\n",
        "### **Deleting Dictionary Items During Iteration in Python**\n",
        "\n",
        "**Short Answer:**  \n",
        "**No**, the code will **not** work correctly if you try to delete dictionary items during iteration. It raises a **`RuntimeError: dictionary changed size during iteration`**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why It Fails**\n",
        "Python dictionaries track their size, and modifying them (adding/removing keys) while iterating breaks the internal iterator, causing an immediate error.\n",
        "\n",
        "#### **Example of the Problem:**\n",
        "```python\n",
        "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "\n",
        "for key in my_dict:\n",
        "    if my_dict[key] % 2 == 0:\n",
        "        del my_dict[key]  # 🚨 RuntimeError\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **How to Fix It**\n",
        "#### **Option 1: Iterate Over a Copy of Keys**\n",
        "```python\n",
        "for key in list(my_dict.keys()):  # Explicit copy\n",
        "    if my_dict[key] % 2 == 0:\n",
        "        del my_dict[key]  # Safe\n",
        "```\n",
        "\n",
        "#### **Option 2: Store Keys to Delete First**\n",
        "```python\n",
        "keys_to_delete = [key for key, value in my_dict.items() if value % 2 == 0]\n",
        "for key in keys_to_delete:\n",
        "    del my_dict[key]\n",
        "```\n",
        "\n",
        "#### **Option 3: Use Dictionary Comprehension (Creates New Dict)**\n",
        "```python\n",
        "my_dict = {k: v for k, v in my_dict.items() if v % 2 != 0}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Takeaways**\n",
        "- **Never modify a dict while iterating directly** over it.  \n",
        "- **Safe methods**:  \n",
        "  - Iterate over a **copy** of keys (`list(my_dict.keys())`).  \n",
        "  - Record keys to delete first, then delete them.  \n",
        "  - Use **dictionary comprehension** for filtering.  \n",
        "\n"
      ],
      "metadata": {
        "id": "ljUv9bIEturq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "for key in list(my_dict.keys()):  # Explicit copy\n",
        "    if my_dict[key] % 2 == 0:\n",
        "        del my_dict[key]\n",
        "print( my_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX0hejRCu380",
        "outputId": "bdda378d-d9c8-4cf3-f1c2-a752d8d0b369"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'c': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q13. What is the difference between Pandas and PySpark?\n",
        "### **Pandas vs. PySpark: Key Differences**\n",
        "\n",
        "| **Feature**               | **Pandas**                                  | **PySpark**                                  |\n",
        "|---------------------------|---------------------------------------------|---------------------------------------------|\n",
        "| **Execution Environment** | Single-machine (RAM-limited)                | Distributed (cluster of machines)           |\n",
        "| **Scalability**           | Handles data that fits in memory (~GBs)     | Handles TBs+ via parallel processing       |\n",
        "| **Lazy Evaluation**       | No (immediate execution)                    | Yes (optimizes execution plan)              |\n",
        "| **Fault Tolerance**       | No (crash = data loss)                      | Yes (via RDD lineage recovery)             |\n",
        "| **Syntax**                | Pythonic (similar to NumPy)                 | SQL-like (with DataFrame API)               |\n",
        "| **Use Cases**             | EDA, small datasets, single-node workflows  | Big data pipelines, ETL, cloud processing  |\n",
        "| **Performance**           | Faster for small data (low overhead)        | Slower for tiny data (cluster setup cost)  |\n",
        "| **Integration**           | Works with Python libraries (Matplotlib, etc.) | Integrates with Hadoop/Hive/S3/etc.       |\n",
        "\n",
        "---\n",
        "\n",
        "### **When to Use Which?**\n",
        "- **Choose Pandas when:**\n",
        "  - Data fits in memory (e.g., <10GB).\n",
        "  - You need quick prototyping or EDA.\n",
        "  - Your workflow uses Python ML libraries (scikit-learn, TensorFlow).\n",
        "\n",
        "- **Choose PySpark when:**\n",
        "  - Data exceeds memory (e.g., TBs of logs).\n",
        "  - You need distributed processing (e.g., ETL pipelines).\n",
        "  - Working in cloud environments (AWS EMR, Databricks).\n",
        "\n",
        "---\n",
        "\n",
        "### **Code Comparison**\n",
        "#### **Pandas (Single-Node)**\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "df_filtered = df[df[\"value\"] > 100]  # In-memory operation\n",
        "```\n",
        "\n",
        "#### **PySpark (Distributed)**\n",
        "```python\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.read.csv(\"s3://bucket/data.csv\")\n",
        "df_filtered = df.filter(df[\"value\"] > 100)  # Lazy evaluation\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Technical Differences**\n",
        "1. **Memory vs. Disk**:  \n",
        "   - Pandas operates in memory.  \n",
        "   - PySpark spills to disk when needed.  \n",
        "\n",
        "2. **Parallelism**:  \n",
        "   - Pandas: Single-threaded (unless using `modin.pandas`).  \n",
        "   - PySpark: Automatically partitions data across nodes.  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "h4bMXa4IuBuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q14. **Step-by-Step Approach to Migrate from Pandas to PySpark**  \n",
        "\n",
        "#### **1. Assess the Current Pipeline**  \n",
        "- **Identify bottlenecks**: Check RAM/CPU usage, slow transformations, and I/O operations.  \n",
        "- **Document dependencies**: Note Pandas functions used (e.g., `.apply()`, `.groupby()`).  \n",
        "- **Data volume**: Confirm if data size justifies PySpark (e.g., >10GB or growing).  \n",
        "\n",
        "#### **2. Set Up PySpark Environment**  \n",
        "- **Cluster configuration**: Choose # of nodes/cores based on data size (e.g., AWS EMR, Databricks).  \n",
        "- **Dependencies**: Install `pyspark` and ensure compatibility with Python libraries (e.g., `numpy`, `scikit-learn`).  \n",
        "\n",
        "#### **3. Rewrite Code Logic**  \n",
        "- **Replace Pandas functions with PySpark equivalents**:  \n",
        "\n",
        "  | **Pandas**               | **PySpark**                          |  \n",
        "  |--------------------------|--------------------------------------|  \n",
        "  | `df[df.col > 100]`       | `df.filter(df.col > 100)`            |  \n",
        "  | `df.groupby().agg()`     | `df.groupBy().agg()` (*case-sensitive*) |  \n",
        "  | `df.apply(func)`         | `df.withColumn(\"new\", udf(func))`    |  \n",
        "  | `pd.merge()`             | `df1.join(df2, on=\"key\")`            |  \n",
        "\n",
        "- **Handle lazy evaluation**: Call `.cache()` for reused DataFrames and `.collect()` only when needed.  \n",
        "\n",
        "#### **4. Optimize Performance**  \n",
        "- **Partitioning**: Repartition data to avoid skew (e.g., `df.repartition(100)`).  \n",
        "- **Broadcast small DataFrames**: Use `broadcast()` for joins with small tables.  \n",
        "- **Avoid UDFs**: Prefer built-in PySpark functions (e.g., `F.expr()` over Python UDFs).  \n",
        "\n",
        "#### **5. Test and Validate**  \n",
        "- **Unit tests**: Verify logic matches Pandas output (e.g., `assert df_pandas.equals(df_spark.toPandas())`).  \n",
        "- **Scale testing**: Run on sample data → full dataset to catch memory/shuffle issues.  \n",
        "- **Data integrity checks**: Compare row counts, NULL values, and key metrics.  \n",
        "\n",
        "#### **6. Deploy and Monitor**  \n",
        "- **Orchestration**: Schedule jobs via Airflow/Luigi (for batch) or Spark Streaming (for real-time).  \n",
        "- **Monitoring**: Track Spark UI for slow tasks, skew, or spills to disk.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Example Migration**  \n",
        "**Pandas**:  \n",
        "```python  \n",
        "df = pd.read_csv(\"data.csv\")  \n",
        "df[\"discount\"] = df[\"price\"].apply(lambda x: x * 0.9)  \n",
        "```  \n",
        "\n",
        "**PySpark**:  \n",
        "```python  \n",
        "from pyspark.sql import functions as F  \n",
        "df = spark.read.csv(\"data.csv\")  \n",
        "df = df.withColumn(\"discount\", F.col(\"price\") * 0.9)  # Avoid UDF for speed  \n",
        "```  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mVFcGSEDwkh3"
      }
    }
  ]
}